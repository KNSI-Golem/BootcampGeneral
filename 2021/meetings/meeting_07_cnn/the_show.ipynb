{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l2, l1\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten, UpSampling2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_BIG_CONV = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras==2.7.0 tensorflow==2.7.0 scikit-image pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "_ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "_ = tf.keras.datasets.cifar10.load_data()\n",
    "_ = tf.keras.datasets.cifar100.load_data()\n",
    "_ = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different dataset this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes[y_train[0][0]])\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First run model from last meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_regularizer = None\n",
    "# bias_regularizer = None\n",
    "kernel_regularizer = regularizers.l2(1e-5)\n",
    "bias_regularizer = regularizers.l2(1e-5)\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "mlp_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = input_shape),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu',\n",
    "                          kernel_regularizer=kernel_regularizer,\n",
    "                          bias_regularizer=bias_regularizer),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer,\n",
    "                          bias_regularizer=bias_regularizer),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax', kernel_regularizer=kernel_regularizer,\n",
    "                          bias_regularizer=bias_regularizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mlp_model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data=(X_test, y_test), \n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "classes_cnt = len(np.unique(y_train))\n",
    "print(input_shape, X_train.shape, classes_cnt)\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(input_shape=input_shape, filters=4, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(filters=4, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(classes_cnt, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.count_params(), mlp_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "classes_cnt = len(np.unique(y_train))\n",
    "print(input_shape, X_train.shape, classes_cnt)\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(input_shape=input_shape, filters=4, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(filters=8, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(filters=8, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(filters=4, kernel_size=(2, 2), padding='same', activation='relu'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dense(classes_cnt, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.count_params(), mlp_model.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger fish showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_fish = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "sample_image = np.asarray(Image.open('cat.img'))\n",
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet accepts images of shape (224, 224, 3)\n",
    "from skimage.transform import resize\n",
    "image = resize(sample_image, (224, 224, 3))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import decode_predictions\n",
    "pred = big_fish.predict(image.reshape(1, *image.shape)) # this reshape is needed. First dim is the batch size\n",
    "label = decode_predictions(pred)[0][0]\n",
    "print(label[1], label[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tensorflow showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "input_shape = X_train.shape[1:]\n",
    "classes_cnt = len(np.unique(y_train))\n",
    "print(input_shape, X_train.shape, classes_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(filters=32, kernel_size=(2, 2), padding='same', activation='relu')(inputs)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(2, 2), padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=128, kernel_size=(2, 2), padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=256, kernel_size=(2, 2), padding='same', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x) \n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x) \n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(classes_cnt, activation='sigmoid')(x) \n",
    "big_conv = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BIG_CONV:\n",
    "    history = big_conv.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))\n",
    "    big_conv.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    big_conv.save_weights(os.path.join(os.getcwd(), 'big_conv.h5'))\n",
    "else:\n",
    "    big_conv.load_weights(os.path.join(os.getcwd(), 'big_conv.h5'))\n",
    "    big_conv.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_conv.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_f, y_train_f), (X_test_f, y_test_f) = tf.keras.datasets.cifar10.load_data()\n",
    "input_shape = X_train_f.shape[1:]\n",
    "classes_cnt = len(np.unique(y_train_f))\n",
    "print(input_shape, X_train.shape, classes_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[idx, layer] for idx, layer in enumerate(big_conv.layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer, layers_cnt = 11, 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = Dense(32, activation='relu')(big_conv.layers[last_layer].output)\n",
    "new_x = Dropout(0.3)(new_x)\n",
    "new_outputs = Dense(classes_cnt, activation='sigmoid')(new_x)\n",
    "new_big_conv_net = Model(inputs=inputs, outputs=new_outputs)\n",
    "new_big_conv_net.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_big_conv_net.evaluate(X_test_f, y_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(last_layer+1):\n",
    "    new_big_conv_net.layers[idx].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_big_conv_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_big_conv_net.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = new_big_conv_net.fit(X_train_f, y_train_f, batch_size=32, epochs=1, validation_data=[X_test_f, y_test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_conv.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_big_conv_net.evaluate(X_test_f, y_test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's change the last layers back to the one from big_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "input_shape = X_train.shape[1:]\n",
    "classes_cnt = len(np.unique(y_train))\n",
    "print(input_shape, X_train.shape, classes_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_x = Dense(256, activation='relu')(new_big_conv_net.layers[last_layer].output)\n",
    "another_x = Dropout(0.3)(another_x)\n",
    "another_outputs = Dense(classes_cnt, activation='sigmoid')(another_x)\n",
    "another_model = Model(inputs=inputs, outputs=another_outputs)\n",
    "for idx in range(last_layer+1, layers_cnt+1):\n",
    "    another_model.layers[idx].set_weights(big_conv.layers[idx].get_weights())\n",
    "another_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_conv.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id(big_conv.layers[-1]) == id(another_model.layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_f, y_train_f), (X_test_f, y_test_f) = tf.keras.datasets.cifar10.load_data()\n",
    "input_shape = X_train_f.shape[1:]\n",
    "classes_cnt = len(np.unique(y_train_f))\n",
    "print(input_shape, X_train.shape, classes_cnt)\n",
    "test_inputs = Input(shape=input_shape)\n",
    "test_x = Conv2D(filters=32, kernel_size=(2, 2), padding='same', activation='relu')(test_inputs)\n",
    "test_x = MaxPool2D(pool_size=(2, 2))(test_x)\n",
    "test_x = Conv2D(filters=64, kernel_size=(2, 2), padding='same', activation='relu')(test_x)\n",
    "test_x = MaxPool2D(pool_size=(2, 2))(test_x)\n",
    "test_x = Conv2D(filters=128, kernel_size=(2, 2), padding='same', activation='relu')(test_x)\n",
    "test_x = MaxPool2D(pool_size=(2, 2))(test_x)\n",
    "test_x = Conv2D(filters=256, kernel_size=(2, 2), padding='same', activation='relu')(test_x)\n",
    "test_x = MaxPool2D(pool_size=(2, 2))(test_x)\n",
    "test_x = Flatten()(test_x)\n",
    "test_x = Dense(1024, activation='relu')(test_x)\n",
    "test_x = Dropout(0.3)(test_x)\n",
    "test_x = Dense(32, activation='relu')(test_x)\n",
    "test_x = Dropout(0.3)(test_x)\n",
    "test_outputs = Dense(classes_cnt, activation='sigmoid')(test_x)\n",
    "test_conv = Model(inputs=test_inputs, outputs=test_outputs)\n",
    "test_conv.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "history = test_conv.fit(X_train_f, y_train_f, batch_size=32, epochs=1, validation_data=[X_test_f, y_test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection & segmentation showcase\n",
    "[Follow this link](https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/mask_rcnn/mask_rcnn_demo.ipynb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "961b6a872976a530e9eb1b75fdcd3f6fe3550ef1322ec7de01e1a8a6f96b7246"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bootcamp_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
