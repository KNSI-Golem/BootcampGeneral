{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca Domowa #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import fetch_openml, make_blobs, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import davies_bouldin_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "### Regresja\n",
    "Ponownie wykorzystamy zbiór danych dotyczący cen mieszkań w Bostonie. Zadanie polega na ocenieniu, które z cech najbardziej nadają się do przewidywania mediany cen, następnie wykorzystaniu algorytmów: drzewa regresji (*DecisionTreeRegressor*) oraz Maszyny Wektorów Nośnych (SVM, a konkretnie SVR czyli Support Vector Regression) do przewidywania wartości mediany cen.\n",
    "\n",
    "Czynności, które należy wykonać to kolejno:\n",
    "\n",
    "1. Załadowanie zbioru danych\n",
    "2. Wytypowanie 5 najbardziej obiecujących cech\n",
    "3. Przygotowanie zbioru danych, zawierającego wybrane cechy, podział na zbiory uczący i testowy\n",
    "4. Trening i ewaluacja drzewa regresji\n",
    "5. Trening i ewaluacja SVRa\n",
    "6. Zastanów się jakie płyną z tego wnioski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Załaduj zbiór dotyczący cen mieszkań w Bostonie, zadbaj o to, żeby etykieta (MEDV) również znalazła się w DataFramie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Wytypuj 5 najbardziej obiecujących cech, na przykład na podstawie macierzy korelacji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Pozbądź się kolumn, których nie chcesz używać\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3cd Dokonaj podziału na zbiór uczący oraz testowy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Wytrenuj model DecisionTreeRegressor i sprawdź jak radzi sobie na zbiorach treningowym i testowym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Wytrenuj model SVR i sprawdź jak radzi sobie na zbiorach treningowym i testowym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "### Grupowanie (analiza skupień)\n",
    "\n",
    "Zadanie polega na wykorzystaniu innego algorytmu grupowania, niż *KMeans*, który został pokazany na spotkaniu, należy sprawdzić również jakie parametry dla wybranego algorytmu dają najlepsze wyniki zgodnie wybraną miarą.\n",
    "\n",
    "Czynności które należy wykonać to kolejno:\n",
    "\n",
    "1. Wybór algorytmu grupowania oraz metryki\n",
    "2. Przeprowadzenie grupowań dla różnych wartości parametrów oraz ocena ich jakości przez wybraną metrykę\n",
    "\n",
    "Tutaj artykuł, w którym można znaleźć więcej informacji zarówno o algorytmach grupowania dostępnych w sklearnie jak i metrykach do ich ewaluacji: https://scikit-learn.org/stable/modules/clustering.html\n",
    "\n",
    "Nie musisz czytać całości, wystarczy, że wybierzesz jeden algorytm i jedną metrykę, np. DBSCAN oraz Davies-Bouldin Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy 4 dobrze odseparowane od siebie chmury punktów, akurat random_state=8 daje dobry wynik\n",
    "X, hidden = make_blobs(n_samples=500, centers=4, n_features=2, random_state=8)\n",
    "\n",
    "# Rysujemy chmury pokolorowane na różne kolory\n",
    "plt.scatter(X[:,0], X[:,1], c=hidden, marker=\"o\", s=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Przeszukiwanie przestrzeni parmetrów w poszukiwaniu takich, które dają najlepsze grupowanie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Wykorzystać otrzymane parametry do uzyskania dobrego grupowania\n",
    "\n",
    "# cluster_labels = ... (tutaj użyj wybranego algorytmu)\n",
    "print(np.unique(cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rysujemy wynik grupowania (lewy wykres) oraz faktyczne ukryte grupy (prawy wykres)\n",
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(20, 5))\n",
    "axs[0].scatter(X[:,0], X[:,1], c=cluster_labels, marker=\"o\", s=25)\n",
    "axs[1].scatter(X[:,0], X[:,1], c=hidden, marker=\"o\", s=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3\n",
    "### Redukcja wymiarowości z wykorzystaniem PCA\n",
    "\n",
    "Zadanie polega na wytrenowaniu klasyfikatorów (*LogisticRegression* oraz *SVC*) na zbiorze danych MNIST.  \n",
    "\n",
    "Pro tip: po to między innymi jest to PCA, żeby nie liczyć tego tydzień."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieramy MNISTa\n",
    "start = time.time()\n",
    "X, y = fetch_openml('mnist_784', data_home='data', version=1, return_X_y=True)\n",
    "end = time.time()\n",
    "print(f\"Download time: {end-start}\")\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizaujemy wartości pikseli do przedziału [0,1]\n",
    "print(np.amin(X),np.amax(X))\n",
    "X = X/255\n",
    "print(np.amin(X),np.amax(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdźmy jak wygląda pojedyncza cyferka\n",
    "plt.imshow(X[1].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Tutaj nalezy wykonać PCA na zbiorze danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzielimy zbiór danych, na zbiór uczący oraz zbiór testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, train_size=60000, test_size=10000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='saga')\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Training time: {end-start}\")\n",
    "\n",
    "# Oceniamy skuteczność modelu na zbiorze testowym\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"Score: {score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Training time: {end-start}\")\n",
    "\n",
    "# Oceniamy skuteczność modelu na zbiorze testowym\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"Score: {score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gratki to koniec :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Bootcamp",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
