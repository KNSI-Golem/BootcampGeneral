{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee036a3",
   "metadata": {},
   "source": [
    "<h2>Run this first</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.7.0 pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3456ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e8027",
   "metadata": {},
   "source": [
    "Download pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b60ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = get_file(\n",
    "    'pretrained_unet.h5',\n",
    "    'https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model/releases/download/v1.0/zf_unet_224.h5',\n",
    "    cache_subdir='models',\n",
    "    file_hash='203146f209baf34ac0d793e1691f1ab7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7ccb8",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69369573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_input(x): \n",
    "    return -(x / 255 - 0.5)\n",
    "\n",
    "def reverse_transform_input(x):\n",
    "    return ((-x + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "def preprocess_masks(x):\n",
    "    return np.round(x / 255).astype(np.uint8) \n",
    "\n",
    "def reverse_transform_masks(x):\n",
    "    return x * 255\n",
    "\n",
    "def preprocess_predictions(x):\n",
    "    return np.round(x).astype(np.uint8) * 255\n",
    "\n",
    "def load_images(path):\n",
    "    images = os.listdir(path)\n",
    "    images = [os.path.join(path, img) for img in images]\n",
    "    return np.array([np.array(Image.open(img).resize((224, 224), resample=Image.NEAREST)) for img in images])\n",
    "\n",
    "def show_images(images=None, masks=None, predictions=None, n_rows=5, figsize=(30, 30), preprocess=False):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if images is not None and len(images.shape) != 4:\n",
    "        n_rows = 1\n",
    "        images = np.expand_dims(images, axis=0)\n",
    "    if masks is not None:\n",
    "        masks = np.squeeze(masks)\n",
    "        if len(masks.shape) != 3:\n",
    "            n_rows = 1\n",
    "            masks = np.expand_dims(masks, axis=0)\n",
    "    if predictions is not None:\n",
    "        predictions = np.squeeze(predictions)\n",
    "        if len(predictions.shape) != 3:\n",
    "            n_rows = 1\n",
    "            predictions = np.expand_dims(predictions, axis=0)\n",
    "\n",
    "    if preprocess:\n",
    "        if images is not None:\n",
    "            images = reverse_transform_input(images)\n",
    "        if masks is not None:\n",
    "            masks = reverse_transform_masks(masks)\n",
    "        if predictions is not None:\n",
    "            predictions = preprocess_predictions(predictions)\n",
    "            \n",
    "    for i in range(n_rows):\n",
    "        if images is not None:\n",
    "            plt.subplot(n_rows, 3, i*3+1)\n",
    "            plt.title(\"Original image\",fontsize=15)\n",
    "            plt.imshow(images[i])\n",
    "            ax = plt.gca()\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "        \n",
    "        if masks is not None:\n",
    "            plt.subplot(n_rows, 3, i*3+2)\n",
    "            plt.title(\"True Mask\",fontsize=15)\n",
    "            plt.imshow(masks[i], cmap='gray')\n",
    "            ax = plt.gca()\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "        \n",
    "        if predictions is not None:\n",
    "            plt.subplot(n_rows, 3, i*3+3)\n",
    "            plt.title(\"Predicted Mask\",fontsize=15)\n",
    "            plt.imshow(predictions[i], cmap='gray')\n",
    "            ax = plt.gca()\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "        \n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8424d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images('homm3_dataset')\n",
    "show_images(images[0], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape # sanity check - dimensions represent (img_count, height, width, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad1ec5",
   "metadata": {},
   "source": [
    "There are 4 channels (the format is RGBA), let's split the alpha channel and the RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images = images[..., :-1]\n",
    "masks = np.expand_dims(images[..., -1], axis=-1)\n",
    "print(rgb_images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bccbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(images[0], masks[0], figsize=(10, 20)) # image should not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgb_images[0].min(), rgb_images[0].max())\n",
    "rgb_images = preprocess_input(rgb_images) #preprocessing step\n",
    "print(rgb_images[0].min(), rgb_images[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(rgb_images[0], figsize=(10, 10)) # colors should change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ff574",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(rgb_images[0], figsize=(10, 10), preprocess=True) # colors shouldn't change because of the preprocess=True flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8816b",
   "metadata": {},
   "source": [
    "The alpha mask may have values ranging from 0 to 255 - let's change it to binary mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(masks.min(), masks.max())\n",
    "masks = preprocess_masks(masks)\n",
    "print(masks.min(), masks.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa402c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(rgb_images[0], masks[0], figsize=(10, 20), preprocess=True) # nothing should change visually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c72a1",
   "metadata": {},
   "source": [
    "<h1>Loading pretrained UNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be936d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of image channels (for example 3 in case of RGB, or 1 for grayscale images)\n",
    "INPUT_CHANNELS = 3\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "def double_conv_layer(x, size, dropout=0.0, batch_norm=True):\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm:\n",
    "        conv = BatchNormalization(axis=3)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    \n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm:\n",
    "        conv = BatchNormalization(axis=3)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv) # dropout that drops whole feature maps instead of individual elements (https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout2D)\n",
    "        \n",
    "    return conv\n",
    "\n",
    "# definition of the model is taken from this here:\n",
    "# https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model/blob/master/zf_unet_224_model.py\n",
    "def ZF_UNET_224(dropout_val=0.2):\n",
    "    inputs = Input((224, 224, INPUT_CHANNELS))\n",
    "    axis = 3\n",
    "    filters = 32\n",
    "\n",
    "    conv_224 = double_conv_layer(inputs, filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=3)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=3)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=3)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=3)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=3)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='final_conv')(up_conv_224)\n",
    "    conv_final = Activation('sigmoid', name='final_activation')(conv_final)\n",
    "\n",
    "    model = Model(inputs, conv_final, name=\"ZF_UNET_224\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZF_UNET_224()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f074f",
   "metadata": {},
   "source": [
    "<h1>Using pretrained model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61934978",
   "metadata": {},
   "source": [
    "So now let's see how our pretrained UNet will work with segmenting our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2306918",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(rgb_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7041f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(rgb_images, masks, preds, preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296071c3",
   "metadata": {},
   "source": [
    "So, as we can see, because the UNet was trained on similar task, its outputs already have some sense even though it has never seen our data before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c71f3",
   "metadata": {},
   "source": [
    "<h1>Fine-tuning Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE = 0.7\n",
    "split = int(images.shape[0] * TRAIN_PERCENTAGE)\n",
    "\n",
    "X_train, y_train = rgb_images[:split], masks[:split]\n",
    "X_test, y_test = rgb_images[split:], masks[split:]\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)\n",
    "print(f'{X_train.shape[0] + X_test.shape[0]} == {images.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "show_images(X_test, y_test, preds, preprocess=True) # plotting before training for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847cd2c6",
   "metadata": {},
   "source": [
    "<h2>TASK</h2>\n",
    "Use pretrained model and fine-tune it on our dataset. The amount of data is really small so remember to freeze some layers. <br><br>\n",
    "<strong>THE GOAL</strong> is to get the accuracy over 98% on test set. Even without fine-tuning the model should get around 97.5% so don't expect much improvement. Check your results with function <i>show_images</i> to make sure predictions don't look worse than before <br><br>\n",
    "<strong>IMPORTANT NOTE:</strong> DO NOT freeze BatchNormalization layers. Transfer learning doesn't work well with frozen BatchNorms (as to why, check here: https://stackoverflow.com/questions/51123198/strange-behaviour-of-the-loss-function-in-keras-model-with-pretrained-convoluti/51124511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6afbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
