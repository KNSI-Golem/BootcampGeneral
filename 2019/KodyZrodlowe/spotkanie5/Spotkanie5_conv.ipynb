{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznanie pojedyńczej cyfry na captchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie danych\n",
    "Dane ułożone są w 10 folderach o nazwach od '0' do '9'. Przeiterujemy po folderach wczytując obrazki z każdego z nich zachowując nazwę folderu jako label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # obrazki\n",
    "    images = []\n",
    "    # etykiety\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        # tworzymy ściężkę do folderu przez połączenie \n",
    "        # ścieżki do folderu z danymi z cyfra od 0 do 9\n",
    "        folder_path = os.path.join(path, str(i)) \n",
    "        \n",
    "        # pętla do iterowania po folderach\n",
    "        for img in os.listdir(folder_path):\n",
    "            \n",
    "            # wczytanie obrazka\n",
    "            image = imread(os.path.join(folder_path, img))\n",
    "            \n",
    "            # zamiana na numpy.ndarray\n",
    "            x = img_to_array(image)\n",
    "            \n",
    "            # średnia zamiani nam kolorowy obrazek na czarnobiały\n",
    "            # Można też skorzystać z funkcji dostępnej w open cv\n",
    "            # która prawdopodobnie zamieni to trochę lepiej ;)\n",
    "            x = np.mean(x, axis = 2)[:, :, np.newaxis]\n",
    "            \n",
    "            # dołączamy obrazek do przykładów treningowych\n",
    "            images.append(x)\n",
    "            labels.append(i)\n",
    "            \n",
    "    # shuffling\n",
    "    indices = np.arange(len(labels))\n",
    "    np.random.shuffle(indices)\n",
    "            \n",
    "    return np.array(images)[indices], np.array(labels)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data('./dane/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wypluło nam 20'000 obrazków w rozmiarze 60x60 i z jednym kanałem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dzielimy dane na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class our_scaler:\n",
    "    '''\n",
    "        w sklearn znajduje się StandardScaler służący do normalizacji danych.\n",
    "        Z jakiegoś powodu nie działał w tym przypadku dlatego napisałem swój :))\n",
    "        std = odchylenie standardowe\n",
    "        mean = średnia\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.mean = 0\n",
    "        self.std = 1\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.mean = np.mean(data)\n",
    "        self.std = np.std(data)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = our_scaler()\n",
    "\n",
    "# ważne jest aby normalizować obydwa zbiory tymi samymi wartościami\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oczekujemy że odchylenia zbioru testowego będzie zbliżone do 1\n",
    "np.std(X_test), np.mean(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wyplotujemy rozkład nasyceń pikseli losowego obrazka\n",
    "plt.hist(X_train[10000].flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzmy że rozkład jest bardzo nie normalny co będzie sprawiało problemy przy uczeniu sieci neuronowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.min(X_train), np.max(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodujemy etykiety do postaci one hot. Wektor one-hot jest n wymiarowym wektorem składającym się z samych zer i jednej jedynki. Długość wektora jest równa ilości różnych etykiet. 3 -> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_hot_targets = np.eye(10)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_train[:5])\n",
    "print(one_hot_targets[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieć neuronowa\n",
    "Zbudujemy konwolucyjną sieć neuronową. W klasycznej sieci neuronowej, na końcu, znajduje się szereg warstw w pełni połączonych.\n",
    "\n",
    "Ten model będzie się prawdopodobnie długo uczył na procesorze (ok. 30 min) dlatego w komórce niżej wczytujemy juz przeuczony przeze mnie model ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tworzenie modeli w kerasie\n",
    "Jest na świecie mało rzeczy łatwiejszych od stworzenia sieci neuronowej w kerasie. Jest to biblioteka stworzona do bezwysiłkowego tworzenia prostych modeli. Do naszych potrzeb będziemy potrzebowali modelu sekwencyjnego Sequential który kieruje wyjście poprzedniej warstwy na wejście następnej. So modelu dodajemy wartswy metodą .add po koleji.\n",
    "\n",
    "**keras.models.Sequential**\n",
    "Model typu sequential, tak samo jak chyba każdy model w kerasie, ma 4 najważniejsze metody:\n",
    "* compile - po dodaniu warstw, metoda rzeczywiście stowrzy nam model. Posiada następujące parametry:\n",
    "    * optimizer - optymalizator np. keras.optimizers.Adam() lub SGD()\n",
    "    * loss - zwykle string zawierający nazwę funkcji np. 'categorical_crossentropy' ale może też być funkcja\n",
    "    * metrics - metryki którymi chcemy oceniać model np. ['accuracy']\n",
    "* fit - dopasowuje model do danych. parametry:\n",
    "    * x = dane wejściowe\n",
    "    * y = labele\n",
    "    * batch_size = wielkość batcha\n",
    "    * epochs = ile razy chcemy pokazać cały dataset naszej sieci neuronowej\n",
    "    * callbacks = bardzo ważne w realnej pracy - dla chętnych w dokumentacji ;)\n",
    "* predict - przepuszcza dane przez sieć\n",
    "    * x = nasze dane\n",
    "    * ma też kilka innych, mniej ważnych parametrów\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**keras.layers.Conv2D**\n",
    "Conv2D jest warstwą konwolucyjną, gwiazdą wieczoru :)\n",
    "\n",
    "parametry:\n",
    "* filters - liczba filtrów w warstwie\n",
    "* kernel_size - wielkość filtra np. (3, 3) lub (5, 5)\n",
    "* strides - na razie nie ważne\n",
    "* padding - na razie nie ważne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sekwencyjny czyli wyjście z \n",
    "# warstwy poprzedniej jest kierowane do następnej\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# dodanie warstwy do modelu. W tym przypadku jest to warstwa konwolucyjna z 32 filtrami rozmiaru 5x5. \n",
    "# Ze względu na rozkład nasycenia pikseli funckją altywacji jest elu zamist relu. Zmniejsza to ilość martwych neuronów.\n",
    "# input_shape jest wielkości (None, None, 1) ponieważ None dane nam mozliwość wrzucenia do sieci większego obrazka.\n",
    "activation_function = 'elu'\n",
    "model.add(keras.layers.Conv2D(32, kernel_size = (5, 5), activation = activation_function, input_shape = (60, 60, 1)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = (5, 5), activation = activation_function))\n",
    "#model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size = (3, 3), activation = activation_function))\n",
    "model.add(keras.layers.MaxPool2D())\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = (5, 5), activation = activation_function))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = (3, 3), activation = activation_function))\n",
    "\n",
    "#model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = (3, 3), activation = activation_function))\n",
    "#model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "# Global max pooling bierze macierz wektorów aktywacji po czym maxuje względem macierzy (wytłumaczę live :)) )\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation = activation_function))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(10))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Softmax())\n",
    "#model.add(keras.layers.Lambda(lambda x: K.clip(x, 1e-4, 0.999)))\n",
    "\n",
    "model.compile(keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-5), \n",
    "              'categorical_crossentropy',\n",
    "             metrics = [keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, one_hot_targets, epochs = 8, batch_size = 64, shuffle = True, validation_split = 0.15, callbacks = [keras.callbacks.TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model_1_pretrained_bootcamp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_path = './model_1_pretrained_bootcamp.h5'\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.imshow(np.squeeze(X_test[i]))\n",
    "    preds = model.predict(X_test[i][np.newaxis, :, :, :])\n",
    "    print('wyjście modelu: ', preds)\n",
    "    print('argmax: \\t', np.argmax(preds))\n",
    "    print('GT: \\t\\t', y_test[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "test_preds = [np.argmax(t) for t in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(confusion_matrix(y_true = y_test, y_pred = test_preds))\n",
    "plt.colorbar()\n",
    "plt.title('Macierz pomyłek')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(confusion_matrix(y_true = y_test, y_pred = test_preds) *(1 - np.eye(10)))\n",
    "plt.colorbar()\n",
    "plt.title('Macierz pomyłek z wyzerowaną przekątną')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
