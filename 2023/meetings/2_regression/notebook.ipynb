{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootcamp 2023 - regresja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso, BayesianRidge, LassoLars, TweedieRegressor, Ridge, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import fetch_openml, fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Przygotowanie datsetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetchujemy datset - obiekt scikitlearn\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konwertujemy obiekt sklearn do pandasa \n",
    "print(type(data))\n",
    "data = data.frame\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co to jest [korelacja](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(data.corr(), annot=True, ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Boxplot](https://builtin.com/data-science/boxplot)\n",
    "\n",
    "![](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/1_boxplots_0.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dzielimy dane na target i features\n",
    "target = 'MedHouseVal'\n",
    "features = [col for col in data.columns.to_list() if col != target]\n",
    "\n",
    "# dla każdego feature rysujemy boxplot\n",
    "fig, axis = plt.subplots(2, data.shape[1]//2, figsize=[20, 10])\n",
    "idx=0;\n",
    "axis=axis.flatten()\n",
    "for feature in features:\n",
    "    sns.boxplot(y=feature, data=data[[feature]], ax=axis[idx])\n",
    "    idx+=1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyrzucamy outlaiery\n",
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_outliers(data, features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, data.shape[1]//2, figsize=[20, 10])\n",
    "idx=0;\n",
    "axis=axis.flatten()\n",
    "for feature in features:\n",
    "    sns.boxplot(y=feature, data=data[[feature]], ax=axis[idx])\n",
    "    idx+=1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dla każdej features rysujemy zależność od targetu\n",
    "fig, axis = plt.subplots(data.shape[1]//2, 2, figsize=[20, 40])\n",
    "idx=0;\n",
    "axis=axis.flatten()\n",
    "for feature in features:\n",
    "    data.plot(y=target, x=feature, kind=\"scatter\", ax=axis[idx])\n",
    "    idx+=1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model liniowy\n",
    "\n",
    "- [Dokumentacja sklearn](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data, model, train_test_ratio, chosen_features, target, random_state=45):\n",
    "    \n",
    "    # dzielimy na train i test\n",
    "    data_train, data_test = train_test_split(data, test_size=train_test_ratio, random_state=random_state)\n",
    "    X_train, X_test = data_train[chosen_features], data_test[chosen_features]\n",
    "    y_train, y_test = data_train[target], data_test[target]\n",
    "    \n",
    "    # cała regresja dzieje się tutaj\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # przewidujemy wartość dla danych testowych\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # liczymy MSE\n",
    "    MSE_train = mean_squared_error(y_train, y_pred_train)\n",
    "    MSE_test = mean_squared_error(y_test, y_pred_test)\n",
    "    print('MSE on training data:', MSE_train)\n",
    "    print('MSE on test data:', MSE_test)\n",
    "    \n",
    "    return model, MSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model liniowy z jedną zmienną\n",
    "chosen_features = ['MedInc']\n",
    "train_test_ratio=0.2\n",
    "\n",
    "model, MSE= build_model(data, LinearRegression(), train_test_ratio, chosen_features, target)\n",
    "\n",
    "# tutaj robię dictionary żeby później móc porównać modele\n",
    "model_dict = {\"linear_1\": MSE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# można sobie zwizualizować\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='MedInc', y=\"MedHouseVal\", data=data[['MedInc','MedHouseVal']])\n",
    "tmp_x = np.array([[data['MedInc'].min(),],[data['MedInc'].max(),]])\n",
    "tmp_y = model.predict(tmp_x)\n",
    "plt.plot(tmp_x, tmp_y, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model liniowy z paroma zmiennymi które wydają się nam najważniejsze\n",
    "\n",
    "chosen_features = ['MedInc', 'AveRooms', 'AveBedrms', 'AveOccup']\n",
    "\n",
    "model, MSE = build_model(data, LinearRegression(), train_test_ratio, chosen_features, target)\n",
    "\n",
    "model_dict[\"linear_2\"] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model liniowy ze wszystkimi featurami\n",
    "\n",
    "chosen_features = features\n",
    "\n",
    "model, MSE = build_model(data, LinearRegression(), train_test_ratio, chosen_features, target)\n",
    "\n",
    "model_dict[\"linear_3\"] = MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model wielomianowy\n",
    "\n",
    "- [PolynomialFeatures() - dokumentacja sklearn](https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions)\n",
    "- [make_pipeline - dokumentacja sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 1 Co robi PolynomialFeatures()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.arange(6).reshape(3, 2)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2 = PolynomialFeatures(2) # stopien wielomianu\n",
    "print(poly2.fit_transform(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3 = PolynomialFeatures(3) \n",
    "print(poly3.fit_transform(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Co robi make_pipeline()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = LinearRegression()\n",
    "example = np.array([[2, 3, 36], [5, 4, 160], [3, 2, 24]])\n",
    "X = example[:, 0:2]\n",
    "Y=example[:, 2]\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#najpierw transformujemy input tak jak na górze\n",
    "X_poly = poly3.fit_transform(X)\n",
    "\n",
    "#potem na nowym inpucie robimy regresje\n",
    "regression_model.fit(X_poly, Y)\n",
    "\n",
    "#wyświetl wpolczynniki ktore policzył model regresji\n",
    "print(regression_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dwa modele nałożone na siebie\n",
    "pipe = make_pipeline(PolynomialFeatures(3),LinearRegression())\n",
    "pipe.fit(X, Y)\n",
    "\n",
    "# możemy zobaczyć jakie modele są w środku\n",
    "print(pipe.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mamy dostep do kazdego modelu z pipeline; patrzymy jakie współczynniki policzył model regresji (spoiler: są takie same)\n",
    "print(pipe.named_steps['linearregression'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Przykłady "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model wielomianowy o stopniu 2\n",
    "degree=2\n",
    "\n",
    "model, MSE = build_model(data, make_pipeline(PolynomialFeatures(degree),LinearRegression()), train_test_ratio, chosen_features, target)\n",
    "\n",
    "model_dict[\"poly_deg2\"] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model wielomianowy o stopniu 3\n",
    "degree=3\n",
    "\n",
    "model, MSE = build_model(data, make_pipeline(PolynomialFeatures(degree),LinearRegression()), train_test_ratio, chosen_features, target)\n",
    "\n",
    "model_dict[\"poly_deg3\"] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model wielomianowy o stopniu 5\n",
    "degree=5\n",
    "model, MSE = build_model(data, make_pipeline(PolynomialFeatures(degree),LinearRegression()),\n",
    "                         train_test_ratio, chosen_features, target)\n",
    "\n",
    "model_dict[\"poly_deg4\"] = MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modele z regularyzacją\n",
    "\n",
    "- [Lasso - dokumentacja sklearn](https://scikit-learn.org/stable/modules/linear_model.html#lasso)\n",
    "- [Ridge - dokumentacja sklearn](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, MSE = build_model(data, Ridge(alpha=0.2), train_test_ratio, chosen_features, target)\n",
    "model_dict[\"ridge\"] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, MSE = build_model(data, Lasso(alpha=0.1), train_test_ratio, chosen_features, target)\n",
    "model_dict[\"lasso\"] = MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5*. Inne modele regresyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poza dopasowywaniem parametrów w funkcjach matematycznych, można dopasowywać je jako parametry dystrybucji w statystyce. Żeby dobrze zrozumieć poniższe przykłady, trzeba mieć sporą wiedzę ze statystyki i algebry, ale warto wiedzieć że takie coś istnieje.\n",
    "\n",
    "- [Lasso LARS](https://en.wikipedia.org/wiki/Least-angle_regression)\n",
    "- [Bayesian Ridge](https://towardsdatascience.com/how-to-build-a-bayesian-ridge-regression-model-with-full-hyperparameter-integration-f4ac2bdaf329)\n",
    "- [Random Forests Regression](https://towardsdatascience.com/random-forest-regression-5f605132d19d) <-to najbardziej polecam przeczytać, zdecydowanie używane najczęściej z tych przykładów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, MSE = build_model(data, LassoLars(alpha=.1, normalize=False), train_test_ratio, chosen_features, target)\n",
    "model_dict[\"lassoLARS\"] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, MSE = build_model(data, BayesianRidge(), train_test_ratio, chosen_features, target)\n",
    "model_dict[\"bayesian_ridge\"] = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, MSE = build_model(data, RandomForestRegressor(), train_test_ratio, chosen_features, target)\n",
    "model_dict[\"radom_forest\"] = MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wnioski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights =  model_dict.values()\n",
    "labels = model_dict.keys()\n",
    "plt.bar(range(len(labels)), heights)\n",
    "plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
